{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T12:59:49.146738Z","iopub.status.busy":"2023-11-03T12:59:49.145867Z","iopub.status.idle":"2023-11-03T13:00:30.387551Z","shell.execute_reply":"2023-11-03T13:00:30.386590Z","shell.execute_reply.started":"2023-11-03T12:59:49.146702Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting datasets==2.11\n","  Downloading datasets-2.11.0-py3-none-any.whl (468 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11) (1.23.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11) (11.0.0)\n","Collecting dill<0.3.7,>=0.3.0 (from datasets==2.11)\n","  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.11) (2.0.2)\n","Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11) (4.66.1)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.11) (3.3.0)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.11) (0.70.15)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11) (2023.9.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.11) (3.8.4)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11) (0.16.4)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets==2.11) (21.3)\n","Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11) (0.18.0)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11) (6.0)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.11) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.11) (3.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.11) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.11) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.11) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.11) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.11) (1.3.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets==2.11) (3.12.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets==2.11) (4.6.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets==2.11) (3.0.9)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.11) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.11) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.11) (2023.7.22)\n","INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n","Collecting multiprocess (from datasets==2.11)\n","  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.11) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.11) (2023.3)\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.11) (2023.3)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.11) (1.16.0)\n","Installing collected packages: dill, multiprocess, datasets\n","  Attempting uninstall: dill\n","    Found existing installation: dill 0.3.7\n","    Uninstalling dill-0.3.7:\n","      Successfully uninstalled dill-0.3.7\n","  Attempting uninstall: multiprocess\n","    Found existing installation: multiprocess 0.70.15\n","    Uninstalling multiprocess-0.70.15:\n","      Successfully uninstalled multiprocess-0.70.15\n","  Attempting uninstall: datasets\n","    Found existing installation: datasets 2.1.0\n","    Uninstalling datasets-2.1.0:\n","      Successfully uninstalled datasets-2.1.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.6 which is incompatible.\n","apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\n","pathos 0.3.1 requires dill>=0.3.7, but you have dill 0.3.6 which is incompatible.\n","pathos 0.3.1 requires multiprocess>=0.70.15, but you have multiprocess 0.70.14 which is incompatible.\n","pymc3 3.11.5 requires numpy<1.22.2,>=1.15.0, but you have numpy 1.23.5 which is incompatible.\n","pymc3 3.11.5 requires scipy<1.8.0,>=1.7.3, but you have scipy 1.11.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed datasets-2.11.0 dill-0.3.6 multiprocess-0.70.14\n","Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.11.0)\n","Requirement already satisfied: transformers[sentencepiece] in /opt/conda/lib/python3.10/site-packages (4.33.0)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\n","Requirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.6)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.2)\n","Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.3.0)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.14)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.9.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.16.4)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\n","Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (3.12.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (2023.6.3)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (0.13.3)\n","Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (0.3.3)\n","Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (0.1.99)\n","Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (3.20.3)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.6.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting rouge_score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hCollecting evaluate\n","  Downloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting portalocker (from sacrebleu)\n","  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n","Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2023.6.3)\n","Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (1.23.5)\n","Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\n","Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (4.9.3)\n","Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\n","Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\n","Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\n","Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.11.0)\n","Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.6)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.0.2)\n","Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.3.0)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.14)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.9.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.16.4)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\n","Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\n","Requirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.6.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.0.9)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.1.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\n","Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Building wheels for collected packages: rouge_score\n","  Building wheel for rouge_score (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=824a7587dced47a4fdf93765afa40bc7cf18d127625e46d9da596541d06d32b9\n","  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n","Successfully built rouge_score\n","Installing collected packages: portalocker, sacrebleu, rouge_score, evaluate\n","Successfully installed evaluate-0.4.1 portalocker-2.8.2 rouge_score-0.1.2 sacrebleu-2.3.1\n"]}],"source":["!pip install datasets==2.11\n","!pip install datasets transformers[sentencepiece]\n","!pip install sacrebleu rouge_score evaluate"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T13:00:30.389858Z","iopub.status.busy":"2023-11-03T13:00:30.389576Z","iopub.status.idle":"2023-11-03T13:00:49.005783Z","shell.execute_reply":"2023-11-03T13:00:49.005052Z","shell.execute_reply.started":"2023-11-03T13:00:30.389833Z"},"id":"MOsHUjgdIrIW","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","/tmp/ipykernel_32/3696305817.py:9: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n","  sacrebleu_metric = load_metric(\"sacrebleu\")\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"870aeb2991934863a2c09472f23c58fb","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"47858cc5cbda4c199f1a4a0b03d40021","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2bbe4e6e69ca4019a7076cde2fc2d8bf","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/9.99k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from datasets import load_dataset, load_metric\n","import pandas as pd\n","import evaluate \n","from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n","from datasets import DatasetDict\n","import numpy as np\n","import evaluate\n","\n","sacrebleu_metric = load_metric(\"sacrebleu\")\n","rouge_metric = evaluate.load('rouge')\n","ter_metric = evaluate.load(\"ter\")"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T13:00:49.007366Z","iopub.status.busy":"2023-11-03T13:00:49.006789Z","iopub.status.idle":"2023-11-03T13:00:49.013882Z","shell.execute_reply":"2023-11-03T13:00:49.013001Z","shell.execute_reply.started":"2023-11-03T13:00:49.007338Z"},"trusted":true},"outputs":[],"source":["def preprocess_dataset(data):\n","    conditions = [data.ref_tox < data.trn_tox ]\n","    values = ['true']\n","    data['swap'] = np.select(conditions, values)\n","    \n","    is_swap = data['swap'] == 'true'\n","    data.loc[is_swap, ['reference', 'translation', 'ref_tox', 'trn_tox']] = (\n","        data.loc[is_swap, ['translation', 'reference', 'trn_tox', 'ref_tox']].values\n","        )\n","    \n","    index_drop = data[(data['ref_tox'] <= 0.8) | (data['trn_tox'] >= 0.2) ].index\n","    data.drop(index_drop, inplace=True)\n","    data.drop(columns=[\"swap\"], axis=1, inplace=True)\n","    return data"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T13:00:49.016976Z","iopub.status.busy":"2023-11-03T13:00:49.016637Z","iopub.status.idle":"2023-11-03T13:01:00.109956Z","shell.execute_reply":"2023-11-03T13:01:00.109129Z","shell.execute_reply.started":"2023-11-03T13:00:49.016925Z"},"trusted":true},"outputs":[],"source":["d = pd.read_table(\"/kaggle/input/paranmt/filtered.tsv\")\n","d = preprocess_dataset(d)\n","d.to_csv(\"converted.csv\")"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T13:01:00.111759Z","iopub.status.busy":"2023-11-03T13:01:00.111352Z","iopub.status.idle":"2023-11-03T13:01:00.131126Z","shell.execute_reply":"2023-11-03T13:01:00.130153Z","shell.execute_reply.started":"2023-11-03T13:01:00.111725Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>reference</th>\n","      <th>translation</th>\n","      <th>similarity</th>\n","      <th>lenght_diff</th>\n","      <th>ref_tox</th>\n","      <th>trn_tox</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>if Alkar floods her with her mental waste, it ...</td>\n","      <td>If Alkar is flooding her with psychic waste, t...</td>\n","      <td>0.785171</td>\n","      <td>0.010309</td>\n","      <td>0.981983</td>\n","      <td>0.014195</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>you're becoming disgusting.</td>\n","      <td>Now you're getting nasty.</td>\n","      <td>0.749687</td>\n","      <td>0.071429</td>\n","      <td>0.999039</td>\n","      <td>0.065473</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>monkey, you have to wake up.</td>\n","      <td>Ah! Monkey, you've got to snap out of it.</td>\n","      <td>0.664333</td>\n","      <td>0.309524</td>\n","      <td>0.994215</td>\n","      <td>0.053362</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>I have orders to kill her.</td>\n","      <td>I've got orders to put her down.</td>\n","      <td>0.726639</td>\n","      <td>0.181818</td>\n","      <td>0.999348</td>\n","      <td>0.009402</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>I'm not gonna have a child... ...with the same...</td>\n","      <td>I'm not going to breed kids with a genetic dis...</td>\n","      <td>0.703185</td>\n","      <td>0.206522</td>\n","      <td>0.950956</td>\n","      <td>0.035846</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Unnamed: 0                                          reference  \\\n","0           0  if Alkar floods her with her mental waste, it ...   \n","1           1                        you're becoming disgusting.   \n","3           3                       monkey, you have to wake up.   \n","4           4                         I have orders to kill her.   \n","5           5  I'm not gonna have a child... ...with the same...   \n","\n","                                         translation  similarity  lenght_diff  \\\n","0  If Alkar is flooding her with psychic waste, t...    0.785171     0.010309   \n","1                          Now you're getting nasty.    0.749687     0.071429   \n","3          Ah! Monkey, you've got to snap out of it.    0.664333     0.309524   \n","4                   I've got orders to put her down.    0.726639     0.181818   \n","5  I'm not going to breed kids with a genetic dis...    0.703185     0.206522   \n","\n","    ref_tox   trn_tox  \n","0  0.981983  0.014195  \n","1  0.999039  0.065473  \n","3  0.994215  0.053362  \n","4  0.999348  0.009402  \n","5  0.950956  0.035846  "]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["d.head()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T13:01:00.132614Z","iopub.status.busy":"2023-11-03T13:01:00.132361Z","iopub.status.idle":"2023-11-03T13:01:03.124201Z","shell.execute_reply":"2023-11-03T13:01:03.123356Z","shell.execute_reply.started":"2023-11-03T13:01:00.132592Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-b03c98139713f04b/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"db562ab8d3394e58b21240d16e5e70f3","version_major":2,"version_minor":0},"text/plain":["Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c909c17b371547909a8a757ef98e026e","version_major":2,"version_minor":0},"text/plain":["Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-b03c98139713f04b/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a2cf9ab5615e4800a1d7beb05f4ad463","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"}],"source":["raw_datasets = load_dataset(\"csv\", data_files=\"/kaggle/working/converted.csv\")\n","raw_datasets = raw_datasets['train'].train_test_split(test_size=1-50000/raw_datasets.num_rows[\"train\"], seed=42)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T13:01:03.125685Z","iopub.status.busy":"2023-11-03T13:01:03.125400Z","iopub.status.idle":"2023-11-03T13:01:03.131645Z","shell.execute_reply":"2023-11-03T13:01:03.130693Z","shell.execute_reply.started":"2023-11-03T13:01:03.125661Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'train': 50000, 'test': 439290}"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["raw_datasets.num_rows"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T13:01:03.133458Z","iopub.status.busy":"2023-11-03T13:01:03.132918Z","iopub.status.idle":"2023-11-03T13:01:03.147642Z","shell.execute_reply":"2023-11-03T13:01:03.146707Z","shell.execute_reply.started":"2023-11-03T13:01:03.133412Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['Unnamed: 0.1', 'Unnamed: 0', 'reference', 'translation', 'similarity', 'lenght_diff', 'ref_tox', 'trn_tox'],\n","        num_rows: 50000\n","    })\n","    test: Dataset({\n","        features: ['Unnamed: 0.1', 'Unnamed: 0', 'reference', 'translation', 'similarity', 'lenght_diff', 'ref_tox', 'trn_tox'],\n","        num_rows: 439290\n","    })\n","})"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["raw_datasets"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T13:01:03.149089Z","iopub.status.busy":"2023-11-03T13:01:03.148788Z","iopub.status.idle":"2023-11-03T13:01:03.154268Z","shell.execute_reply":"2023-11-03T13:01:03.153411Z","shell.execute_reply.started":"2023-11-03T13:01:03.149058Z"},"id":"8T9V5cFkf4pf","trusted":true},"outputs":[],"source":["#model_checkpoint = \"s-nlp/t5-paranmt-detox\"\n","model_checkpoint = \"s-nlp/bart-base-detox\"\n","#model_checkpoint = \"t5-base\""]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T13:01:03.158632Z","iopub.status.busy":"2023-11-03T13:01:03.157961Z","iopub.status.idle":"2023-11-03T13:01:10.207501Z","shell.execute_reply":"2023-11-03T13:01:10.206697Z","shell.execute_reply.started":"2023-11-03T13:01:03.158596Z"},"id":"eXNLu_-nIrJI","trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"67f92425bd14458695d48093121c374d","version_major":2,"version_minor":0},"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/295 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c315de8fb1a64108a881b10629e76228","version_major":2,"version_minor":0},"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/1.71k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"df5350a2af6843c1a12abadbb98b47bd","version_major":2,"version_minor":0},"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eab7388d2bfd4cb3a82fa9c5b055eedc","version_major":2,"version_minor":0},"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"fe040b87f18d49b0b81de2715080f7b9","version_major":2,"version_minor":0},"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"466a7c3290bb493aa5ffec6c57323e40","version_major":2,"version_minor":0},"text/plain":["Downloading (…)in/added_tokens.json:   0%|          | 0.00/16.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b5260dc46c2d4ca7848881f535634c13","version_major":2,"version_minor":0},"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["from transformers import AutoTokenizer\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T13:01:10.209388Z","iopub.status.busy":"2023-11-03T13:01:10.208727Z","iopub.status.idle":"2023-11-03T13:01:10.214237Z","shell.execute_reply":"2023-11-03T13:01:10.213273Z","shell.execute_reply.started":"2023-11-03T13:01:10.209353Z"},"id":"e1smcFpFf4pv","trusted":true},"outputs":[],"source":["if model_checkpoint in [\"t5-small\", \"t5-base\", \"t5-larg\", \"t5-3b\", \"t5-11b\"]:\n","    prefix = \"translate tox to detox: \"\n","else:\n","    prefix = \"\""]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T13:01:10.215620Z","iopub.status.busy":"2023-11-03T13:01:10.215357Z","iopub.status.idle":"2023-11-03T13:01:10.223714Z","shell.execute_reply":"2023-11-03T13:01:10.222904Z","shell.execute_reply.started":"2023-11-03T13:01:10.215597Z"},"id":"vc0BSBLIIrJQ","trusted":true},"outputs":[],"source":["max_input_length = 128\n","max_target_length = 128\n","\n","def preprocess_function_extra(tokenizer, model):\n","    def preprocess_function(examples):\n","        inputs = [prefix + ex for ex in examples[\"reference\"]]\n","        targets = [ex for ex in examples[\"translation\"]]\n","        model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n","\n","        # Setup the tokenizer for targets\n","        with tokenizer.as_target_tokenizer():\n","            labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n","\n","        model_inputs[\"labels\"] = labels[\"input_ids\"]\n","        return model_inputs\n","    return preprocess_function"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T13:01:10.225463Z","iopub.status.busy":"2023-11-03T13:01:10.224798Z","iopub.status.idle":"2023-11-03T13:01:11.557128Z","shell.execute_reply":"2023-11-03T13:01:11.555067Z","shell.execute_reply.started":"2023-11-03T13:01:10.225436Z"},"id":"-b70jh26IrJS","outputId":"acd3a42d-985b-44ee-9daa-af5d944ce1d9","trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'preprocess_function' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpreprocess_function\u001b[49m(raw_datasets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m][:\u001b[38;5;241m2\u001b[39m])\n","\u001b[0;31mNameError\u001b[0m: name 'preprocess_function' is not defined"]}],"source":["#preprocess_function(raw_datasets['train'][:2])"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T13:01:50.655822Z","iopub.status.busy":"2023-11-03T13:01:50.655453Z","iopub.status.idle":"2023-11-03T13:01:50.732729Z","shell.execute_reply":"2023-11-03T13:01:50.731994Z","shell.execute_reply.started":"2023-11-03T13:01:50.655792Z"},"trusted":true},"outputs":[],"source":["raw_datasets_train = raw_datasets['train'].train_test_split(test_size=0.3, seed=42)\n","raw_datasets_test = raw_datasets_train['test'].train_test_split(test_size=0.5, seed=42)\n","\n","\n","ds_splits = DatasetDict({\n","    'train': raw_datasets_train['train'],\n","    'valid': raw_datasets_test['train'],\n","    'test': raw_datasets_test['test']\n","})"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T13:01:52.061374Z","iopub.status.busy":"2023-11-03T13:01:52.060605Z","iopub.status.idle":"2023-11-03T13:01:52.067620Z","shell.execute_reply":"2023-11-03T13:01:52.066635Z","shell.execute_reply.started":"2023-11-03T13:01:52.061341Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['Unnamed: 0.1', 'Unnamed: 0', 'reference', 'translation', 'similarity', 'lenght_diff', 'ref_tox', 'trn_tox'],\n","        num_rows: 35000\n","    })\n","    valid: Dataset({\n","        features: ['Unnamed: 0.1', 'Unnamed: 0', 'reference', 'translation', 'similarity', 'lenght_diff', 'ref_tox', 'trn_tox'],\n","        num_rows: 7500\n","    })\n","    test: Dataset({\n","        features: ['Unnamed: 0.1', 'Unnamed: 0', 'reference', 'translation', 'similarity', 'lenght_diff', 'ref_tox', 'trn_tox'],\n","        num_rows: 7500\n","    })\n","})"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["ds_splits"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T13:02:11.281757Z","iopub.status.busy":"2023-11-03T13:02:11.281358Z","iopub.status.idle":"2023-11-03T13:02:14.902029Z","shell.execute_reply":"2023-11-03T13:02:14.900982Z","shell.execute_reply.started":"2023-11-03T13:02:11.281722Z"},"trusted":true},"outputs":[],"source":["model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T13:02:14.903518Z","iopub.status.busy":"2023-11-03T13:02:14.903218Z","iopub.status.idle":"2023-11-03T13:02:24.497971Z","shell.execute_reply":"2023-11-03T13:02:24.497021Z","shell.execute_reply.started":"2023-11-03T13:02:14.903492Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/35000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3660: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/7500 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/7500 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["tokenized_datasets = ds_splits.map(preprocess_function_extra(tokenizer,model), batched=True)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T13:02:24.501239Z","iopub.status.busy":"2023-11-03T13:02:24.500801Z","iopub.status.idle":"2023-11-03T13:02:24.506801Z","shell.execute_reply":"2023-11-03T13:02:24.505769Z","shell.execute_reply.started":"2023-11-03T13:02:24.501201Z"},"trusted":true},"outputs":[],"source":["source_lang = \"toxic\"\n","target_lang = \"detoxic\"\n","batch_size = 16"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T13:02:24.508355Z","iopub.status.busy":"2023-11-03T13:02:24.508030Z","iopub.status.idle":"2023-11-03T13:02:24.567080Z","shell.execute_reply":"2023-11-03T13:02:24.566189Z","shell.execute_reply.started":"2023-11-03T13:02:24.508324Z"},"id":"Bliy8zgjIrJY","trusted":true},"outputs":[],"source":["model_name = model_checkpoint.split(\"/\")[-1]\n","args = Seq2SeqTrainingArguments(\n","    f\"{model_name}-finetuned-{source_lang}-to-{target_lang}\",\n","    evaluation_strategy = \"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    weight_decay=0.01,\n","    save_total_limit=3,\n","    num_train_epochs=2,\n","    predict_with_generate=True,\n","    fp16=True,\n","    push_to_hub=False,\n","    report_to=\"none\"\n",")"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T13:02:24.568609Z","iopub.status.busy":"2023-11-03T13:02:24.568218Z","iopub.status.idle":"2023-11-03T13:02:24.573032Z","shell.execute_reply":"2023-11-03T13:02:24.572127Z","shell.execute_reply.started":"2023-11-03T13:02:24.568584Z"},"id":"LkVVH5aTf4pz","trusted":true},"outputs":[],"source":["data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T13:02:24.574672Z","iopub.status.busy":"2023-11-03T13:02:24.574242Z","iopub.status.idle":"2023-11-03T13:02:24.585779Z","shell.execute_reply":"2023-11-03T13:02:24.584889Z","shell.execute_reply.started":"2023-11-03T13:02:24.574641Z"},"id":"UmvbnJ9JIrJd","trusted":true},"outputs":[],"source":["def postprocess_text(preds, labels):\n","    preds = [pred.strip() for pred in preds]\n","    labels = [[label.strip()] for label in labels]\n","\n","    return preds, labels\n","\n","def compute_metric_with_extra(tokenizer):\n","    def compute_metrics(eval_preds):\n","        preds, labels = eval_preds\n","        if isinstance(preds, tuple):\n","            preds = preds[0]\n","        decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n","\n","        # Replace -100 in the labels as we can't decode them.\n","        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","        # Some simple post-processing\n","        decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n","\n","        sacrebleu_result = sacrebleu_metric.compute(predictions=decoded_preds, references=decoded_labels)\n","        rouge_result = rouge_metric.compute(predictions=decoded_preds, references=decoded_labels)\n","        ter_result = ter_metric.compute(predictions=decoded_preds, references=decoded_labels)\n","\n","        result = {\"bleu\": sacrebleu_result[\"score\"],\n","                \"rouge1\": rouge_result[\"rouge1\"],\n","                 \"rouge2\": rouge_result[\"rouge2\"],\n","                 \"TER\": ter_result[\"score\"]}\n","        print(result)\n","        prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n","        result[\"gen_len\"] = np.mean(prediction_lens)\n","        result = {k: round(v, 4) for k, v in result.items()}\n","        return result\n","    return compute_metrics"]},{"cell_type":"markdown","metadata":{"id":"rXuFTAzDIrJe"},"source":["Then we just need to pass all of this along with our datasets to the `Seq2SeqTrainer`:"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T13:02:24.587211Z","iopub.status.busy":"2023-11-03T13:02:24.586913Z","iopub.status.idle":"2023-11-03T13:02:28.953064Z","shell.execute_reply":"2023-11-03T13:02:28.952210Z","shell.execute_reply.started":"2023-11-03T13:02:24.587188Z"},"id":"imY1oC3SIrJf","trusted":true},"outputs":[],"source":["trainer = Seq2SeqTrainer(\n","    model,\n","    args,\n","    train_dataset=tokenized_datasets[\"train\"],\n","    eval_dataset=tokenized_datasets[\"valid\"],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metric_with_extra(tokenizer)\n",")"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T13:02:28.954565Z","iopub.status.busy":"2023-11-03T13:02:28.954235Z","iopub.status.idle":"2023-11-03T13:21:25.315964Z","shell.execute_reply":"2023-11-03T13:21:25.315069Z","shell.execute_reply.started":"2023-11-03T13:02:28.954538Z"},"id":"uNx5pyRlIrJh","outputId":"077e661e-d36c-469b-89b8-7ff7f73541ec","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='4376' max='4376' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4376/4376 18:54, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Rouge1</th>\n","      <th>Rouge2</th>\n","      <th>Ter</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.969300</td>\n","      <td>1.805549</td>\n","      <td>23.402400</td>\n","      <td>0.575800</td>\n","      <td>0.347500</td>\n","      <td>63.943700</td>\n","      <td>19.944500</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>1.783200</td>\n","      <td>1.773347</td>\n","      <td>23.677700</td>\n","      <td>0.577700</td>\n","      <td>0.350900</td>\n","      <td>63.643000</td>\n","      <td>19.931700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'bleu': 23.402445155928408, 'rouge1': 0.57583991140112, 'rouge2': 0.34753189314992283, 'TER': 63.94365423691581}\n","{'bleu': 23.67771648137215, 'rouge1': 0.5776906677466493, 'rouge2': 0.35092409882206455, 'TER': 63.64297874677357}\n"]},{"data":{"text/plain":["TrainOutput(global_step=4376, training_loss=1.9123117701445027, metrics={'train_runtime': 1136.0219, 'train_samples_per_second': 61.619, 'train_steps_per_second': 3.852, 'total_flos': 1457413042176000.0, 'train_loss': 1.9123117701445027, 'epoch': 2.0})"]},"execution_count":25,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T13:21:25.319251Z","iopub.status.busy":"2023-11-03T13:21:25.318984Z","iopub.status.idle":"2023-11-03T13:25:43.108290Z","shell.execute_reply":"2023-11-03T13:25:43.107336Z","shell.execute_reply.started":"2023-11-03T13:21:25.319229Z"},"trusted":true},"outputs":[{"data":{"text/html":[],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'bleu': 23.67771648137215, 'rouge1': 0.5776906677466493, 'rouge2': 0.35092409882206455, 'TER': 63.64297874677357}\n"]},{"data":{"text/plain":["{'eval_loss': 1.7733469009399414,\n"," 'eval_bleu': 23.6777,\n"," 'eval_rouge1': 0.5777,\n"," 'eval_rouge2': 0.3509,\n"," 'eval_TER': 63.643,\n"," 'eval_gen_len': 19.9317,\n"," 'eval_runtime': 257.7786,\n"," 'eval_samples_per_second': 29.095,\n"," 'eval_steps_per_second': 1.819,\n"," 'epoch': 2.0}"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["trainer.evaluate()"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T13:25:43.109825Z","iopub.status.busy":"2023-11-03T13:25:43.109539Z","iopub.status.idle":"2023-11-03T13:25:44.109993Z","shell.execute_reply":"2023-11-03T13:25:44.109002Z","shell.execute_reply.started":"2023-11-03T13:25:43.109800Z"},"id":"t2Km5TXVf4p2","trusted":true},"outputs":[],"source":["trainer.save_model()"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T13:25:44.111609Z","iopub.status.busy":"2023-11-03T13:25:44.111270Z","iopub.status.idle":"2023-11-03T13:30:02.517061Z","shell.execute_reply":"2023-11-03T13:30:02.516178Z","shell.execute_reply.started":"2023-11-03T13:25:44.111571Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'bleu': 24.223545816197163, 'rouge1': 0.5789883810317589, 'rouge2': 0.3537359428406176, 'TER': 62.88037230432555}\n"]}],"source":["predictions, labels, metrics = trainer.predict(tokenized_datasets[\"test\"], metric_key_prefix=\"predict\")"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T13:30:02.518661Z","iopub.status.busy":"2023-11-03T13:30:02.518382Z","iopub.status.idle":"2023-11-03T13:30:02.678434Z","shell.execute_reply":"2023-11-03T13:30:02.677597Z","shell.execute_reply.started":"2023-11-03T13:30:02.518637Z"},"trusted":true},"outputs":[],"source":["my_predictions = tokenizer.batch_decode(\n","                    predictions, skip_special_tokens=True, clean_up_tokenization_spaces=True\n","                )"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T13:30:02.679800Z","iopub.status.busy":"2023-11-03T13:30:02.679518Z","iopub.status.idle":"2023-11-03T13:30:02.686302Z","shell.execute_reply":"2023-11-03T13:30:02.685297Z","shell.execute_reply.started":"2023-11-03T13:30:02.679775Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['Scary, seven feet tall, with sharp teeth.',\n"," \"I'm a joke?\",\n"," 'The British... a lot of them are not welcome here.',\n"," 'You could be a beautiful pig.',\n"," \"that's why I keep chasing you.\",\n"," \"oh, my God, they're so gross.\",\n"," \"Since the bomb didn't explode, he must have been caught and executed.\",\n"," 'But you have to promise me that the next time you sleep with your wife, you',\n"," '\"my daughter wanted to marry a bad guy once,\" Crosby said darkly.',\n"," \"in fact, it's about the entire 2nd Mass and how you're going to\",\n"," \"he'll remove the cancerous part of the tongue and then replace it with a strip\",\n"," \"girls, let's go sit with the bullet.\",\n"," \"You're gonna strangle me?\",\n"," 'Quiet, boy.',\n"," \"There are still some barbarians hiding on the island, but I'm sure we'll\"]"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["my_predictions[:15]"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T13:30:02.687721Z","iopub.status.busy":"2023-11-03T13:30:02.687372Z","iopub.status.idle":"2023-11-03T13:30:02.756114Z","shell.execute_reply":"2023-11-03T13:30:02.755188Z","shell.execute_reply.started":"2023-11-03T13:30:02.687697Z"},"trusted":true},"outputs":[{"data":{"text/plain":["['terrible, seven feet tall, with sharp teeth.',\n"," \"I'm the fucking joke?\",\n"," 'the British...... a lot of them are not welcome here.',\n"," 'you could be a beautiful pig.',\n"," \"That's why I keep ducking you.\",\n"," \"God, they're so gross.\",\n"," \"since the bomb didn't explode, he must have been caught and executed.\",\n"," 'but you have to promise me that the next time you fuck your wife, you have to call you \"Jay.\"',\n"," '\"My daughter wanted to marry a pissant once,\" said Crosby darkly.',\n"," \"In fact, it's about the entire 2nd Mass and how you're gonna crawl back to whatever dung heap you came from and leave us all alone.\",\n"," \"Uh,he'il remove the cancerous part of the tongue,and then reconstru it with a strip of flesh from your legs.\",\n"," \"Girls, let's go sit with the bullet.\",\n"," 'you gonna strangle me?',\n"," 'shut up, boy.',\n"," \"there are still some barbarians in hiding on the island, but I'm sure we'll find them soon, and we'll kill them, every Barbar we don't charge, will be sent by ship along with the rest of the peaceful barbarians back to their country.\"]"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["ds_splits[\"test\"][\"reference\"][:15]"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T13:30:02.757596Z","iopub.status.busy":"2023-11-03T13:30:02.757301Z","iopub.status.idle":"2023-11-03T13:30:02.765719Z","shell.execute_reply":"2023-11-03T13:30:02.764855Z","shell.execute_reply.started":"2023-11-03T13:30:02.757571Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[{'loss': 2.1844,\n","  'learning_rate': 1.7719378427787937e-05,\n","  'epoch': 0.23,\n","  'step': 500},\n"," {'loss': 2.0407,\n","  'learning_rate': 1.543875685557587e-05,\n","  'epoch': 0.46,\n","  'step': 1000},\n"," {'loss': 1.9981,\n","  'learning_rate': 1.3153564899451555e-05,\n","  'epoch': 0.69,\n","  'step': 1500},\n"," {'loss': 1.9693,\n","  'learning_rate': 1.0872943327239488e-05,\n","  'epoch': 0.91,\n","  'step': 2000},\n"," {'eval_loss': 1.8055486679077148,\n","  'eval_bleu': 23.4024,\n","  'eval_rouge1': 0.5758,\n","  'eval_rouge2': 0.3475,\n","  'eval_TER': 63.9437,\n","  'eval_gen_len': 19.9445,\n","  'eval_runtime': 259.0059,\n","  'eval_samples_per_second': 28.957,\n","  'eval_steps_per_second': 1.811,\n","  'epoch': 1.0,\n","  'step': 2188},\n"," {'loss': 1.876,\n","  'learning_rate': 8.587751371115174e-06,\n","  'epoch': 1.14,\n","  'step': 2500},\n"," {'loss': 1.7728,\n","  'learning_rate': 6.30255941499086e-06,\n","  'epoch': 1.37,\n","  'step': 3000},\n"," {'loss': 1.7884,\n","  'learning_rate': 4.017367458866545e-06,\n","  'epoch': 1.6,\n","  'step': 3500},\n"," {'loss': 1.7832,\n","  'learning_rate': 1.7321755027422304e-06,\n","  'epoch': 1.83,\n","  'step': 4000},\n"," {'eval_loss': 1.7733469009399414,\n","  'eval_bleu': 23.6777,\n","  'eval_rouge1': 0.5777,\n","  'eval_rouge2': 0.3509,\n","  'eval_TER': 63.643,\n","  'eval_gen_len': 19.9317,\n","  'eval_runtime': 259.3419,\n","  'eval_samples_per_second': 28.919,\n","  'eval_steps_per_second': 1.808,\n","  'epoch': 2.0,\n","  'step': 4376},\n"," {'train_runtime': 1136.0219,\n","  'train_samples_per_second': 61.619,\n","  'train_steps_per_second': 3.852,\n","  'total_flos': 1457413042176000.0,\n","  'train_loss': 1.9123117701445027,\n","  'epoch': 2.0,\n","  'step': 4376},\n"," {'eval_loss': 1.7733469009399414,\n","  'eval_bleu': 23.6777,\n","  'eval_rouge1': 0.5777,\n","  'eval_rouge2': 0.3509,\n","  'eval_TER': 63.643,\n","  'eval_gen_len': 19.9317,\n","  'eval_runtime': 257.7786,\n","  'eval_samples_per_second': 29.095,\n","  'eval_steps_per_second': 1.819,\n","  'epoch': 2.0,\n","  'step': 4376}]"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["trainer.state.log_history"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T13:30:02.767264Z","iopub.status.busy":"2023-11-03T13:30:02.766977Z","iopub.status.idle":"2023-11-03T13:30:02.774548Z","shell.execute_reply":"2023-11-03T13:30:02.773622Z","shell.execute_reply.started":"2023-11-03T13:30:02.767241Z"},"trusted":true},"outputs":[],"source":["train_loss = []\n","eval_loss = []\n","step = []\n","eval_step = []\n","for log in trainer.state.log_history:\n","    if \"loss\" in log.keys():\n","        train_loss.append(log[\"loss\"])\n","        step.append(log[\"step\"])\n","    if \"eval_loss\" in log.keys():\n","        eval_loss.append(log[\"eval_loss\"])\n","        eval_step.append(log[\"step\"])"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T13:30:02.775991Z","iopub.status.busy":"2023-11-03T13:30:02.775647Z","iopub.status.idle":"2023-11-03T13:30:02.786027Z","shell.execute_reply":"2023-11-03T13:30:02.785103Z","shell.execute_reply.started":"2023-11-03T13:30:02.775937Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[{'loss': 2.1844,\n","  'learning_rate': 1.7719378427787937e-05,\n","  'epoch': 0.23,\n","  'step': 500},\n"," {'loss': 2.0407,\n","  'learning_rate': 1.543875685557587e-05,\n","  'epoch': 0.46,\n","  'step': 1000},\n"," {'loss': 1.9981,\n","  'learning_rate': 1.3153564899451555e-05,\n","  'epoch': 0.69,\n","  'step': 1500},\n"," {'loss': 1.9693,\n","  'learning_rate': 1.0872943327239488e-05,\n","  'epoch': 0.91,\n","  'step': 2000},\n"," {'eval_loss': 1.8055486679077148,\n","  'eval_bleu': 23.4024,\n","  'eval_rouge1': 0.5758,\n","  'eval_rouge2': 0.3475,\n","  'eval_TER': 63.9437,\n","  'eval_gen_len': 19.9445,\n","  'eval_runtime': 259.0059,\n","  'eval_samples_per_second': 28.957,\n","  'eval_steps_per_second': 1.811,\n","  'epoch': 1.0,\n","  'step': 2188},\n"," {'loss': 1.876,\n","  'learning_rate': 8.587751371115174e-06,\n","  'epoch': 1.14,\n","  'step': 2500},\n"," {'loss': 1.7728,\n","  'learning_rate': 6.30255941499086e-06,\n","  'epoch': 1.37,\n","  'step': 3000},\n"," {'loss': 1.7884,\n","  'learning_rate': 4.017367458866545e-06,\n","  'epoch': 1.6,\n","  'step': 3500},\n"," {'loss': 1.7832,\n","  'learning_rate': 1.7321755027422304e-06,\n","  'epoch': 1.83,\n","  'step': 4000},\n"," {'eval_loss': 1.7733469009399414,\n","  'eval_bleu': 23.6777,\n","  'eval_rouge1': 0.5777,\n","  'eval_rouge2': 0.3509,\n","  'eval_TER': 63.643,\n","  'eval_gen_len': 19.9317,\n","  'eval_runtime': 259.3419,\n","  'eval_samples_per_second': 28.919,\n","  'eval_steps_per_second': 1.808,\n","  'epoch': 2.0,\n","  'step': 4376},\n"," {'train_runtime': 1136.0219,\n","  'train_samples_per_second': 61.619,\n","  'train_steps_per_second': 3.852,\n","  'total_flos': 1457413042176000.0,\n","  'train_loss': 1.9123117701445027,\n","  'epoch': 2.0,\n","  'step': 4376},\n"," {'eval_loss': 1.7733469009399414,\n","  'eval_bleu': 23.6777,\n","  'eval_rouge1': 0.5777,\n","  'eval_rouge2': 0.3509,\n","  'eval_TER': 63.643,\n","  'eval_gen_len': 19.9317,\n","  'eval_runtime': 257.7786,\n","  'eval_samples_per_second': 29.095,\n","  'eval_steps_per_second': 1.819,\n","  'epoch': 2.0,\n","  'step': 4376}]"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["trainer.state.log_history"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","\n","plt.plot(step, train_loss)\n","plt.plot(eval_step, eval_loss)\n","plt.legend([\"train_loss\", \"eval_loss\"], loc =\"lower right\") \n","plt.show()"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2023-11-03T13:30:03.102224Z","iopub.status.busy":"2023-11-03T13:30:03.101929Z","iopub.status.idle":"2023-11-03T13:30:04.426733Z","shell.execute_reply":"2023-11-03T13:30:04.425443Z","shell.execute_reply.started":"2023-11-03T13:30:03.102199Z"},"trusted":true},"outputs":[{"ename":"RuntimeError","evalue":"Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[36], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are nigger\u001b[39m\u001b[38;5;124m\"\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39minput_ids\n\u001b[0;32m----> 2\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(\n\u001b[1;32m      4\u001b[0m                     predictions, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, clean_up_tokenization_spaces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      5\u001b[0m                 )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1492\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m   1485\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA decoder-only architecture is being used, but right-padding was detected! For correct \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1486\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneration results, please set `padding_side=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m` when initializing the tokenizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1487\u001b[0m         )\n\u001b[1;32m   1489\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n\u001b[1;32m   1490\u001b[0m     \u001b[38;5;66;03m# if model is encoder decoder encoder_outputs are created\u001b[39;00m\n\u001b[1;32m   1491\u001b[0m     \u001b[38;5;66;03m# and added to `model_kwargs`\u001b[39;00m\n\u001b[0;32m-> 1492\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_encoder_decoder_kwargs_for_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_input_name\u001b[49m\n\u001b[1;32m   1494\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# 5. Prepare `input_ids` which will be used for auto-regressive generation\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:661\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001b[0;34m(self, inputs_tensor, model_kwargs, model_input_name)\u001b[0m\n\u001b[1;32m    659\u001b[0m encoder_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    660\u001b[0m encoder_kwargs[model_input_name] \u001b[38;5;241m=\u001b[39m inputs_tensor\n\u001b[0;32m--> 661\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m]: ModelOutput \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mencoder_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_kwargs\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:818\u001b[0m, in \u001b[0;36mBartEncoder.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to specify either input_ids or inputs_embeds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    817\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 818\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_scale\n\u001b[1;32m    820\u001b[0m embed_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_positions(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    821\u001b[0m embed_pos \u001b[38;5;241m=\u001b[39m embed_pos\u001b[38;5;241m.\u001b[39mto(inputs_embeds\u001b[38;5;241m.\u001b[39mdevice)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2210\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2204\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2205\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2206\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2207\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2208\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2209\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)"]}],"source":["inputs = tokenizer(\"You are nigger\", return_tensors=\"pt\").input_ids\n","predictions = model.generate(inputs)\n","tokenizer.batch_decode(\n","                    predictions, skip_special_tokens=True, clean_up_tokenization_spaces=True\n","                )"]}],"metadata":{"colab":{"name":"Translation","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
