{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install datasets==2.11\n!pip install datasets transformers[sentencepiece]\n!pip install sacrebleu rouge_score evaluate","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-05T12:56:07.385300Z","iopub.execute_input":"2023-11-05T12:56:07.386147Z","iopub.status.idle":"2023-11-05T12:56:42.860973Z","shell.execute_reply.started":"2023-11-05T12:56:07.386115Z","shell.execute_reply":"2023-11-05T12:56:42.859793Z"},"trusted":true},"execution_count":88,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets==2.11 in /opt/conda/lib/python3.10/site-packages (2.11.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11) (1.23.5)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11) (11.0.0)\nRequirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11) (0.3.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.11) (2.0.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.11) (3.3.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.11) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11) (2023.9.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.11) (3.8.4)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11) (0.16.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets==2.11) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11) (0.18.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.11) (6.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.11) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.11) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.11) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.11) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.11) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.11) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.11) (1.3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets==2.11) (3.12.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets==2.11) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets==2.11) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.11) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.11) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.11) (2023.7.22)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.11) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.11) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.11) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.11) (1.16.0)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.11.0)\nRequirement already satisfied: transformers[sentencepiece] in /opt/conda/lib/python3.10/site-packages (4.33.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.23.5)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill<0.3.7,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.0.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.3.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (2023.9.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.8.4)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.16.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (3.12.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (2023.6.3)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (0.3.3)\nRequirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (0.1.99)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]) (3.20.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: sacrebleu in /opt/conda/lib/python3.10/site-packages (2.3.1)\nRequirement already satisfied: rouge_score in /opt/conda/lib/python3.10/site-packages (0.1.2)\nRequirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.1)\nRequirement already satisfied: portalocker in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2.8.2)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2023.6.3)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (1.23.5)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (4.9.3)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.11.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.0.2)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.3.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.14)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2023.9.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.16.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.18.0)\nRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (11.0.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.8.4)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.12.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.7.22)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import logging\n\nlogging.set_verbosity_error()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-05T12:56:42.863167Z","iopub.execute_input":"2023-11-05T12:56:42.863510Z","iopub.status.idle":"2023-11-05T12:56:42.870390Z","shell.execute_reply.started":"2023-11-05T12:56:42.863480Z","shell.execute_reply":"2023-11-05T12:56:42.869429Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"from datasets import load_dataset, load_metric\nimport pandas as pd\nimport evaluate \nfrom transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\nfrom datasets import DatasetDict\nimport numpy as np\nimport evaluate\n\nsacrebleu_metric = load_metric(\"sacrebleu\")\nrouge_metric = evaluate.load('rouge')\nter_metric = evaluate.load(\"ter\")","metadata":{"execution":{"iopub.status.busy":"2023-11-05T12:56:42.871883Z","iopub.execute_input":"2023-11-05T12:56:42.872234Z","iopub.status.idle":"2023-11-05T12:56:44.981957Z","shell.execute_reply.started":"2023-11-05T12:56:42.872202Z","shell.execute_reply":"2023-11-05T12:56:44.981146Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"def preprocess_dataset(data):\n    conditions = [data.ref_tox < data.trn_tox ]\n    values = ['true']\n    data['swap'] = np.select(conditions, values)\n    \n    is_swap = data['swap'] == 'true'\n    data.loc[is_swap, ['reference', 'translation', 'ref_tox', 'trn_tox']] = (\n        data.loc[is_swap, ['translation', 'reference', 'trn_tox', 'ref_tox']].values\n        )\n    \n    index_drop = data[(data['ref_tox'] <= 0.8) | (data['trn_tox'] >= 0.2) ].index\n    data.drop(index_drop, inplace=True)\n    data.drop(columns=[\"swap\"], axis=1, inplace=True)\n    return data","metadata":{"execution":{"iopub.status.busy":"2023-11-05T12:56:44.984297Z","iopub.execute_input":"2023-11-05T12:56:44.984594Z","iopub.status.idle":"2023-11-05T12:56:44.991629Z","shell.execute_reply.started":"2023-11-05T12:56:44.984569Z","shell.execute_reply":"2023-11-05T12:56:44.990656Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"d = pd.read_table(\"/kaggle/input/paranmt/filtered.tsv\")\nd = preprocess_dataset(d)\nd.to_csv(\"converted.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-11-05T12:56:44.992939Z","iopub.execute_input":"2023-11-05T12:56:44.993560Z","iopub.status.idle":"2023-11-05T12:56:55.106042Z","shell.execute_reply.started":"2023-11-05T12:56:44.993525Z","shell.execute_reply":"2023-11-05T12:56:55.104896Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"d.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-05T12:56:55.109305Z","iopub.execute_input":"2023-11-05T12:56:55.110049Z","iopub.status.idle":"2023-11-05T12:56:55.123361Z","shell.execute_reply.started":"2023-11-05T12:56:55.110021Z","shell.execute_reply":"2023-11-05T12:56:55.122415Z"},"trusted":true},"execution_count":93,"outputs":[{"execution_count":93,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0                                          reference  \\\n0           0  if Alkar floods her with her mental waste, it ...   \n1           1                        you're becoming disgusting.   \n3           3                       monkey, you have to wake up.   \n4           4                         I have orders to kill her.   \n5           5  I'm not gonna have a child... ...with the same...   \n\n                                         translation  similarity  lenght_diff  \\\n0  If Alkar is flooding her with psychic waste, t...    0.785171     0.010309   \n1                          Now you're getting nasty.    0.749687     0.071429   \n3          Ah! Monkey, you've got to snap out of it.    0.664333     0.309524   \n4                   I've got orders to put her down.    0.726639     0.181818   \n5  I'm not going to breed kids with a genetic dis...    0.703185     0.206522   \n\n    ref_tox   trn_tox  \n0  0.981983  0.014195  \n1  0.999039  0.065473  \n3  0.994215  0.053362  \n4  0.999348  0.009402  \n5  0.950956  0.035846  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>reference</th>\n      <th>translation</th>\n      <th>similarity</th>\n      <th>lenght_diff</th>\n      <th>ref_tox</th>\n      <th>trn_tox</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>if Alkar floods her with her mental waste, it ...</td>\n      <td>If Alkar is flooding her with psychic waste, t...</td>\n      <td>0.785171</td>\n      <td>0.010309</td>\n      <td>0.981983</td>\n      <td>0.014195</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>you're becoming disgusting.</td>\n      <td>Now you're getting nasty.</td>\n      <td>0.749687</td>\n      <td>0.071429</td>\n      <td>0.999039</td>\n      <td>0.065473</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>monkey, you have to wake up.</td>\n      <td>Ah! Monkey, you've got to snap out of it.</td>\n      <td>0.664333</td>\n      <td>0.309524</td>\n      <td>0.994215</td>\n      <td>0.053362</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>I have orders to kill her.</td>\n      <td>I've got orders to put her down.</td>\n      <td>0.726639</td>\n      <td>0.181818</td>\n      <td>0.999348</td>\n      <td>0.009402</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>I'm not gonna have a child... ...with the same...</td>\n      <td>I'm not going to breed kids with a genetic dis...</td>\n      <td>0.703185</td>\n      <td>0.206522</td>\n      <td>0.950956</td>\n      <td>0.035846</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"raw_datasets = load_dataset(\"csv\", data_files=\"/kaggle/working/converted.csv\")\nraw_datasets = raw_datasets['train'].train_test_split(test_size=1-200000/raw_datasets.num_rows[\"train\"], seed=42)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T12:56:55.124458Z","iopub.execute_input":"2023-11-05T12:56:55.124737Z","iopub.status.idle":"2023-11-05T12:56:57.606782Z","shell.execute_reply.started":"2023-11-05T12:56:55.124713Z","shell.execute_reply":"2023-11-05T12:56:57.605931Z"},"trusted":true},"execution_count":94,"outputs":[{"name":"stdout","text":"Downloading and preparing dataset csv/default to /root/.cache/huggingface/datasets/csv/default-8f3615130d62798d/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9339ff55d42a4ca99abe030144ad0914"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30adab76786542ad82e505eceffe8dda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset csv downloaded and prepared to /root/.cache/huggingface/datasets/csv/default-8f3615130d62798d/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c40b420f07d747beaa43bb61ad1b220a"}},"metadata":{}}]},{"cell_type":"code","source":"raw_datasets_train = raw_datasets['train'].train_test_split(test_size=0.3, seed=42)\nraw_datasets_test = raw_datasets_train['test'].train_test_split(test_size=0.5, seed=42)\n\n\nds_splits = DatasetDict({\n    'train': raw_datasets_train['train'],\n    'valid': raw_datasets_test['train'],\n    'test': raw_datasets_test['test']\n})","metadata":{"execution":{"iopub.status.busy":"2023-11-05T12:56:57.607969Z","iopub.execute_input":"2023-11-05T12:56:57.608228Z","iopub.status.idle":"2023-11-05T12:56:57.725248Z","shell.execute_reply.started":"2023-11-05T12:56:57.608206Z","shell.execute_reply":"2023-11-05T12:56:57.724488Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"model_checkpoint = \"bert-base-uncased\"","metadata":{"execution":{"iopub.status.busy":"2023-11-05T12:56:57.726260Z","iopub.execute_input":"2023-11-05T12:56:57.726547Z","iopub.status.idle":"2023-11-05T12:56:57.730779Z","shell.execute_reply.started":"2023-11-05T12:56:57.726522Z","shell.execute_reply":"2023-11-05T12:56:57.729864Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T12:56:57.734072Z","iopub.execute_input":"2023-11-05T12:56:57.734335Z","iopub.status.idle":"2023-11-05T12:56:57.913389Z","shell.execute_reply.started":"2023-11-05T12:56:57.734312Z","shell.execute_reply":"2023-11-05T12:56:57.912354Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"def tokenize_function(examples):\n    return tokenizer(examples[\"translation\"])","metadata":{"execution":{"iopub.status.busy":"2023-11-05T12:56:57.914703Z","iopub.execute_input":"2023-11-05T12:56:57.915067Z","iopub.status.idle":"2023-11-05T12:56:57.919995Z","shell.execute_reply.started":"2023-11-05T12:56:57.915034Z","shell.execute_reply":"2023-11-05T12:56:57.919130Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"tokenized_datasets = ds_splits.map(tokenize_function, batched=True, num_proc=4,\n                                   remove_columns=[\"Unnamed: 0.1\", \"Unnamed: 0\",\n                                                  \"reference\", \"translation\", \"similarity\",\n                                                   \"lenght_diff\", \"trn_tox\", \"ref_tox\"\n                                                  ])","metadata":{"execution":{"iopub.status.busy":"2023-11-05T12:56:57.921353Z","iopub.execute_input":"2023-11-05T12:56:57.921816Z","iopub.status.idle":"2023-11-05T12:57:10.307867Z","shell.execute_reply.started":"2023-11-05T12:56:57.921784Z","shell.execute_reply":"2023-11-05T12:57:10.306899Z"},"trusted":true},"execution_count":99,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/140000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/30000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/30000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}]},{"cell_type":"code","source":"tokenized_datasets[\"train\"][1]","metadata":{"execution":{"iopub.status.busy":"2023-11-05T12:57:10.309652Z","iopub.execute_input":"2023-11-05T12:57:10.309978Z","iopub.status.idle":"2023-11-05T12:57:10.318674Z","shell.execute_reply.started":"2023-11-05T12:57:10.309948Z","shell.execute_reply":"2023-11-05T12:57:10.317776Z"},"trusted":true},"execution_count":100,"outputs":[{"execution_count":100,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [101, 2002, 2001, 4855, 4933, 2043, 1045, 2288, 2045, 1012, 102],\n 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModelForMaskedLM\n\nmodel = AutoModelForMaskedLM.from_pretrained(\"distilroberta-base\")\nblock_size = 128","metadata":{"execution":{"iopub.status.busy":"2023-11-05T12:57:10.319789Z","iopub.execute_input":"2023-11-05T12:57:10.320076Z","iopub.status.idle":"2023-11-05T12:57:11.848503Z","shell.execute_reply.started":"2023-11-05T12:57:10.320051Z","shell.execute_reply":"2023-11-05T12:57:11.847415Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"def group_texts(examples):\n    # Concatenate all texts.\n    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n    total_length = len(concatenated_examples[list(examples.keys())[0]])\n    # We drop the small remainder, we could add padding if the model supported it instead of this drop, you can\n        # customize this part to your needs.\n    total_length = (total_length // block_size) * block_size\n    # Split by chunks of max_len.\n    result = {\n        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n        for k, t in concatenated_examples.items()\n    }\n    result[\"labels\"] = result[\"input_ids\"].copy()\n    return result","metadata":{"execution":{"iopub.status.busy":"2023-11-05T12:57:11.849876Z","iopub.execute_input":"2023-11-05T12:57:11.850194Z","iopub.status.idle":"2023-11-05T12:57:11.857103Z","shell.execute_reply.started":"2023-11-05T12:57:11.850168Z","shell.execute_reply":"2023-11-05T12:57:11.856116Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"ds_splits = tokenized_datasets.map(\n    group_texts,\n    batched=True,\n    batch_size=1000,\n    num_proc=4,\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T12:57:11.858277Z","iopub.execute_input":"2023-11-05T12:57:11.858623Z","iopub.status.idle":"2023-11-05T12:57:24.452536Z","shell.execute_reply.started":"2023-11-05T12:57:11.858597Z","shell.execute_reply":"2023-11-05T12:57:24.451334Z"},"trusted":true},"execution_count":103,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/140000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/30000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map (num_proc=4):   0%|          | 0/30000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DataCollatorForLanguageModeling\n\ndata_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)","metadata":{"execution":{"iopub.status.busy":"2023-11-05T12:57:24.456612Z","iopub.execute_input":"2023-11-05T12:57:24.457021Z","iopub.status.idle":"2023-11-05T12:57:24.466885Z","shell.execute_reply.started":"2023-11-05T12:57:24.456980Z","shell.execute_reply":"2023-11-05T12:57:24.465931Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\n\ntraining_args = TrainingArguments(\n    output_dir=\"my_awesome_eli5_mlm_model\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-5,\n    num_train_epochs=10,\n    weight_decay=0.01,\n    report_to=\"none\"\n    #push_to_hub=True,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=ds_splits[\"train\"],\n    eval_dataset=ds_splits[\"test\"],\n    data_collator=data_collator,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-11-05T12:57:24.469891Z","iopub.execute_input":"2023-11-05T12:57:24.470180Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"{'loss': 5.9812, 'learning_rate': 1.9527186761229316e-05, 'epoch': 0.24}\n{'loss': 5.1615, 'learning_rate': 1.905437352245863e-05, 'epoch': 0.47}\n{'loss': 4.901, 'learning_rate': 1.8581560283687945e-05, 'epoch': 0.71}\n{'loss': 4.7497, 'learning_rate': 1.810874704491726e-05, 'epoch': 0.95}\n{'eval_loss': 4.622377395629883, 'eval_runtime': 16.3309, 'eval_samples_per_second': 222.645, 'eval_steps_per_second': 27.861, 'epoch': 1.0}\n{'loss': 4.6491, 'learning_rate': 1.7635933806146574e-05, 'epoch': 1.18}\n{'loss': 4.5076, 'learning_rate': 1.716312056737589e-05, 'epoch': 1.42}\n{'loss': 4.4798, 'learning_rate': 1.6690307328605203e-05, 'epoch': 1.65}\n{'loss': 4.4188, 'learning_rate': 1.6217494089834514e-05, 'epoch': 1.89}\n{'eval_loss': 4.31002950668335, 'eval_runtime': 16.1663, 'eval_samples_per_second': 224.912, 'eval_steps_per_second': 28.145, 'epoch': 2.0}\n{'loss': 4.3831, 'learning_rate': 1.5744680851063832e-05, 'epoch': 2.13}\n{'loss': 4.3073, 'learning_rate': 1.5271867612293146e-05, 'epoch': 2.36}\n{'loss': 4.3074, 'learning_rate': 1.4799054373522459e-05, 'epoch': 2.6}\n{'loss': 4.2541, 'learning_rate': 1.4326241134751775e-05, 'epoch': 2.84}\n{'eval_loss': 4.133467197418213, 'eval_runtime': 16.2567, 'eval_samples_per_second': 223.661, 'eval_steps_per_second': 27.988, 'epoch': 3.0}\n{'loss': 4.2241, 'learning_rate': 1.3853427895981088e-05, 'epoch': 3.07}\n{'loss': 4.1549, 'learning_rate': 1.3380614657210403e-05, 'epoch': 3.31}\n{'loss': 4.1619, 'learning_rate': 1.2907801418439719e-05, 'epoch': 3.55}\n{'loss': 4.1504, 'learning_rate': 1.2434988179669031e-05, 'epoch': 3.78}\n{'eval_loss': 4.021623611450195, 'eval_runtime': 16.1217, 'eval_samples_per_second': 225.535, 'eval_steps_per_second': 28.223, 'epoch': 4.0}\n{'loss': 4.0741, 'learning_rate': 1.1962174940898346e-05, 'epoch': 4.02}\n{'loss': 4.0548, 'learning_rate': 1.1489361702127662e-05, 'epoch': 4.26}\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nfrom transformers import RobertaForSequenceClassification, RobertaTokenizer\nfrom transformers import AutoTokenizer, BertForMaskedLM, BertTokenizer\n\n\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\nmodel = BertForMaskedLM.from_pretrained(\"/kaggle/working/my_awesome_eli5_mlm_model/checkpoint-500\")\n\ndef predict_toxicity(texts, device='cpu', clf_name = 's-nlp/roberta_toxicity_classifier_v1'):\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    clf = RobertaForSequenceClassification.from_pretrained(clf_name).to(device)\n    clf_tokenizer = RobertaTokenizer.from_pretrained(clf_name)\n    with torch.inference_mode():\n        inputs = clf_tokenizer(texts, return_tensors='pt', padding=True).to(clf.device)\n        out = torch.softmax(clf(**inputs).logits, -1)[:, 1].cpu().numpy()\n    return out\n\n\ndef mask_toxic(sentence, threshold=0.3):\n    words = sentence.split()\n    probabilities = predict_toxicity(words)\n    text_prep = []\n    toxic_indexes = []\n    for _word, _prob in zip(words, probabilities):\n        if _prob > threshold:\n            text_prep.append(\"[MASK]\")\n        else:\n            text_prep.append(_word)\n    text_prep = \" \".join(text_prep)\n    tokenized = tokenizer(text_prep, return_tensors=\"pt\")\n    return tokenized\n\ndef get_mask_index(inputs):\n    mask_token_indexes = (inputs.input_ids == tokenizer.mask_token_id)[0].nonzero(as_tuple=True)[0]\n    return mask_token_indexes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def infer(sentence):\n    inputs = mask_toxic(sentence)\n    with torch.no_grad():\n        logits = model(**inputs).logits\n    mask_indexes = get_mask_index(inputs)\n    for mask_token_index in mask_indexes:\n        predicted_token_id = logits[0, mask_token_index].argmax(axis=-1)\n        inputs.input_ids[0][mask_token_index] = predicted_token_id\n    decoded_sentence = tokenizer.decode(inputs.input_ids[0][1:-1])\n    return decoded_sentence","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_table('/kaggle/input/paranmt/filtered.tsv')\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import trange\nfrom transformers import logging\nimport torch\n\nlogging.set_verbosity_error()\n\ntoxic_sentences = df.reference[:10].tolist()\ntoxic_sentences_list = [[t] for t in toxic_sentences]\ndetoxified_text = []\nresult = {\n    \"bleu\": 0,\n    \"rouge1\": 0,\n    \"rouge2\": 0,\n    \"TER\": 0\n}\nn = len(toxic_sentences)\nfor i in trange(len(toxic_sentences)):\n    detoxified_sentence = infer(toxic_sentences[i])\n    #words = toxic_sentences[i].split()\n    #toxic_scores = predict_toxicity(words)\n    #detoxified_sentence = \" \".join([sentence for sentence, score in zip(words, toxic_scores) if score < threshold])\n    detoxified_text.append(detoxified_sentence)\n\nresult[\"bleu\"] = sacrebleu_metric.compute(predictions=detoxified_text, references=toxic_sentences_list)[\"score\"]\nrouge_score = rouge_metric.compute(predictions=detoxified_text, references=toxic_sentences_list)\nresult[\"rouge1\"] = rouge_score[\"rouge1\"]\nresult[\"rouge2\"] = rouge_score[\"rouge2\"]\nresult[\"TER\"] = ter_metric.compute(predictions=detoxified_text, references=toxic_sentences_list)[\"score\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(result)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"infer(\"He is strange\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\npd.DataFrame(result, index=[0]).head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}