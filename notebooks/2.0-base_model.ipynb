{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(577777, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>similarity</th>\n",
       "      <th>lenght_diff</th>\n",
       "      <th>ref_tox</th>\n",
       "      <th>trn_tox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>336880</th>\n",
       "      <td>336880</td>\n",
       "      <td>I'll deal with that little weasel myself.</td>\n",
       "      <td>I'll take care of this guy myself.</td>\n",
       "      <td>0.607365</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.923489</td>\n",
       "      <td>0.000165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407228</th>\n",
       "      <td>407228</td>\n",
       "      <td>Don't shoot him.</td>\n",
       "      <td>don't shoot.</td>\n",
       "      <td>0.899540</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.803848</td>\n",
       "      <td>0.004890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150143</th>\n",
       "      <td>150143</td>\n",
       "      <td>Knew that you had no chance of killing me.</td>\n",
       "      <td>he knew you had no chance to kill me.</td>\n",
       "      <td>0.908300</td>\n",
       "      <td>0.116279</td>\n",
       "      <td>0.186780</td>\n",
       "      <td>0.816266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409806</th>\n",
       "      <td>409806</td>\n",
       "      <td>And why the fuck isn't this war ending?</td>\n",
       "      <td>and why doesn't the war end?</td>\n",
       "      <td>0.886870</td>\n",
       "      <td>0.275000</td>\n",
       "      <td>0.997234</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96207</th>\n",
       "      <td>96207</td>\n",
       "      <td>Pompous sod, aren't you?</td>\n",
       "      <td>you're a pompous bastard, aren't you?</td>\n",
       "      <td>0.798035</td>\n",
       "      <td>0.342105</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.999495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328534</th>\n",
       "      <td>328534</td>\n",
       "      <td>Prick.</td>\n",
       "      <td>cock.</td>\n",
       "      <td>0.731666</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.819907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427601</th>\n",
       "      <td>427601</td>\n",
       "      <td>This guy's gonna kill again, and we don't know...</td>\n",
       "      <td>he's going to kill again and we don't know any...</td>\n",
       "      <td>0.942406</td>\n",
       "      <td>0.059701</td>\n",
       "      <td>0.982934</td>\n",
       "      <td>0.256473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79341</th>\n",
       "      <td>79341</td>\n",
       "      <td>if you were taken hostage, you would've fucked...</td>\n",
       "      <td>if he had kept you hostage, you would have com...</td>\n",
       "      <td>0.805749</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.995495</td>\n",
       "      <td>0.040181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101726</th>\n",
       "      <td>101726</td>\n",
       "      <td>You know, it's a damn shame you can't take thi...</td>\n",
       "      <td>it's a hell of a shame you can't accept that.</td>\n",
       "      <td>0.736532</td>\n",
       "      <td>0.132075</td>\n",
       "      <td>0.988483</td>\n",
       "      <td>0.001434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468741</th>\n",
       "      <td>468741</td>\n",
       "      <td>What is she, a superhero or a softcore porno?</td>\n",
       "      <td>what is he, a superhero or a porn actress?</td>\n",
       "      <td>0.822621</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.058013</td>\n",
       "      <td>0.717966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                          reference  \\\n",
       "336880      336880          I'll deal with that little weasel myself.   \n",
       "407228      407228                                   Don't shoot him.   \n",
       "150143      150143         Knew that you had no chance of killing me.   \n",
       "409806      409806            And why the fuck isn't this war ending?   \n",
       "96207        96207                           Pompous sod, aren't you?   \n",
       "328534      328534                                             Prick.   \n",
       "427601      427601  This guy's gonna kill again, and we don't know...   \n",
       "79341        79341  if you were taken hostage, you would've fucked...   \n",
       "101726      101726  You know, it's a damn shame you can't take thi...   \n",
       "468741      468741      What is she, a superhero or a softcore porno?   \n",
       "\n",
       "                                              translation  similarity  \\\n",
       "336880                 I'll take care of this guy myself.    0.607365   \n",
       "407228                                       don't shoot.    0.899540   \n",
       "150143              he knew you had no chance to kill me.    0.908300   \n",
       "409806                       and why doesn't the war end?    0.886870   \n",
       "96207               you're a pompous bastard, aren't you?    0.798035   \n",
       "328534                                              cock.    0.731666   \n",
       "427601  he's going to kill again and we don't know any...    0.942406   \n",
       "79341   if he had kept you hostage, you would have com...    0.805749   \n",
       "101726      it's a hell of a shame you can't accept that.    0.736532   \n",
       "468741         what is he, a superhero or a porn actress?    0.822621   \n",
       "\n",
       "        lenght_diff   ref_tox   trn_tox  \n",
       "336880     0.166667  0.923489  0.000165  \n",
       "407228     0.235294  0.803848  0.004890  \n",
       "150143     0.116279  0.186780  0.816266  \n",
       "409806     0.275000  0.997234  0.000052  \n",
       "96207      0.342105  0.002058  0.999495  \n",
       "328534     0.142857  0.002022  0.819907  \n",
       "427601     0.059701  0.982934  0.256473  \n",
       "79341      0.060606  0.995495  0.040181  \n",
       "101726     0.132075  0.988483  0.001434  \n",
       "468741     0.065217  0.058013  0.717966  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/dmitrii/vscode_projects/PMLDL/Assignment1/data/raw/filtered.tsv', sep='\\t', encoding='utf-8')\n",
    "print(df.shape)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "import evaluate\n",
    "from tqdm import trange\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "\n",
    "def predict_toxicity(texts, device='cpu', clf_name = 's-nlp/roberta_toxicity_classifier_v1'):\n",
    "    \"\"\"\n",
    "    This function predict toxicity of the words\n",
    "\n",
    "    Args:\n",
    "        texts (_type_): _description_\n",
    "        device (str, optional): _description_. Defaults to 'cpu'.\n",
    "        clf_name (str, optional): _description_. Defaults to 's-nlp/roberta_toxicity_classifier_v1'.\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    clf = RobertaForSequenceClassification.from_pretrained(clf_name).to(device)\n",
    "    clf_tokenizer = RobertaTokenizer.from_pretrained(clf_name)\n",
    "    with torch.inference_mode():\n",
    "        inputs = clf_tokenizer(texts, return_tensors='pt', padding=True).to(clf.device)\n",
    "        out = torch.softmax(clf(**inputs).logits, -1)[:, 1].cpu().numpy()\n",
    "    return out\n",
    "\n",
    "def delete_toxic(df, \n",
    "                 threshold=0.5, \n",
    "                 size=20, \n",
    "                 ):\n",
    "    sacrebleu_metric = load_metric(\"sacrebleu\")\n",
    "    rouge_metric = evaluate.load('rouge')\n",
    "    ter_metric = evaluate.load(\"ter\")\n",
    "    print(df.head())\n",
    "    toxic_sentences = df.reference[:size].tolist()\n",
    "    toxic_sentences_list = [[t] for t in toxic_sentences]\n",
    "    detoxified_text = []\n",
    "    result = {\n",
    "        \"bleu\": 0,\n",
    "        \"rouge1\": 0,\n",
    "        \"rouge2\": 0,\n",
    "        \"TER\": 0\n",
    "    }\n",
    "    n = len(toxic_sentences)\n",
    "    for i in trange(len(toxic_sentences)):\n",
    "        words = toxic_sentences[i].split()\n",
    "        toxic_scores = predict_toxicity(words)\n",
    "        detoxified_sentence = \" \".join([sentence for sentence, score in zip(words, toxic_scores) if score < threshold])\n",
    "        detoxified_text.append(detoxified_sentence)\n",
    "\n",
    "    result[\"bleu\"] = sacrebleu_metric.compute(predictions=detoxified_text, references=toxic_sentences_list)[\"score\"]\n",
    "    rouge_score = rouge_metric.compute(predictions=detoxified_text, references=toxic_sentences_list)\n",
    "    result[\"rouge1\"] = rouge_score[\"rouge1\"]\n",
    "    result[\"rouge2\"] = rouge_score[\"rouge2\"]\n",
    "    result[\"TER\"] = ter_metric.compute(predictions=detoxified_text, references=toxic_sentences_list)[\"score\"]\n",
    "    # Let's print last 5 predictions\n",
    "    print(result)\n",
    "    return detoxified_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delete_toxic(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
